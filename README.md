# Tackling Imbalanced Data with Predicted Probabilities
Most classification algorithms are able to output predicted probabilities. These predicted probabilities provide an additional model-tuning mechanism that could help boost prediction performance on imbalanced data.Â However, the predicted probabilities need to be calibrated before they may be used to indicate the optimal probability threshold to maximise a scoring metric of choice.

This article discusses the differences in predicted probabilities across five machine learning algorithms, namely Logistic Regression, Naive Bayes, Random Forest, Support Vector Classification and XG Boost. It demonstrates how predicted probabilities may be used to improve these models' performance in a case study. The data is the 2014 Portuguese bank marketing dataset, where the target variable is successful subscriptions to a term deposit. The probability of a "yes" in the target variable however is just 11.27%.
